{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b67e092-a573-4b1c-9d2d-1093f2938449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import myllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffff78-ad6e-4d38-a083-60323051bc0f",
   "metadata": {},
   "source": [
    "## Chinese caption test: result: bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b9a4d1-6155-453d-8712-dccf61e5f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = None\n",
    "with Image.open('/Users/chengyanru/Downloads/data/.similarity_cache/SPC-20240111/VID_20231122_143012_thumbnail_7b28dbeceb9fe4c09ae0b3b01ad826db.jpg'\n",
    "               ) as img_:\n",
    "    img_.load()\n",
    "    img = img_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984276f3-4333-4354-8055-8f6bf4cb4d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  yuanzhoulvpi/vit-gpt2-image-chinese-captioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengyanru/.miniconda3/envs/ai_album/lib/python3.8/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['这 个 夏 天, 我 们 一 起 来 看 看 吧!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = myllm.ImageCaptionerChinese()\n",
    "\n",
    "c.caption(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2b1ff-afab-4a09-9919-05eb77a640fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35877b7c-785a-434d-b479-a32702e0e2dc",
   "metadata": {},
   "source": [
    "## Chinese translation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88cb8133-c452-4198-ac6b-c556dd23fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = myllm.MyTranslator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3810ac40-9fd2-4817-80f0-6372ca07010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengyanru/.miniconda3/envs/ai_album/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:1248: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "/Users/chengyanru/.miniconda3/envs/ai_album/lib/python3.8/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'灰墙前的一个人'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.translate('A Man Standing In Front Of A Gray Wall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e18701-d8e1-47b3-804c-d35d3baae351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "934b9d71-37b4-4504-bb12-b9b229b02a1f",
   "metadata": {},
   "source": [
    "## Uform test caption instructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae90b5-d854-4311-99cb-3bf8b33c9c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7958fd2e4abe42e88154d72a75a8707e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/742 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45284cecade4ffb90f0aae8e5611569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/40.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad522abf6fd47b182146a727c88e15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66114f988c649eb99974eba371206e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from uform.gen_model import VLMForCausalLM, VLMProcessor\n",
    "\n",
    "model = VLMForCausalLM.from_pretrained(\"unum-cloud/uform-gen-chat\")\n",
    "processor = VLMProcessor.from_pretrained(\"unum-cloud/uform-gen-chat\")\n",
    "\n",
    "prompt = \"What do you see?\"\n",
    "image = Image.open('/Users/chengyanru/Downloads/data/.similarity_cache/SPC-20240111/VID_20231122_143012_thumbnail_7b28dbeceb9fe4c09ae0b3b01ad826db.jpg')\n",
    "\n",
    "inputs = processor(texts=[prompt], images=[image], return_tensors=\"pt\")\n",
    "with torch.inference_mode():\n",
    "     output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "        max_new_tokens=128,\n",
    "        eos_token_id=32001,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "decoded_text = processor.batch_decode(output[:, prompt_len:])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3879c-43d7-4722-afbc-d7b327e6f95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
